\chapter{Development of full-stack microscopy}
\color{red}
\paragraph*{}In the previous chapters, biophysical measurements were carried out in commercial instruments with proprietary software from the original equipment manufacturers. The acquisition software was not directly integrate-able with the image analysis pipeline written with standard scientific python libraries. To fully integrate the software pipelines in Python, the microscope software has to be written from scratch. Micro-manager is an open-source microscope control framework, that readily supports a large number of devices. The MMCore API of the micro-manager can be used to manipulate the microscope in Python. This establishes the basis for data acquisition in Python, which can then be combined with analysis in a closed loop to develop microscope software from scratch.


\section{Microscope software from scratch}
\paragraph*{} Existing microscope software requires a human to perform various tasks associated with the microscope operation, such as scanning the sample visually and identifying regions of interest for imaging objects in the sample. It is error-prone and stressful for the human biologist to manually comb through the sample to find regions of interest and define them as fields of interest. Scanning the sample for objects manually with an eye can also expose the sample to a large amount of light, depleting the photon budget and photobleaching the fluorophores or creating destructive photo-toxicity artefacts in living samples \cite{scherf2015smart}. 

\paragraph*{}In a traditional system, multidimensional raw image data of the sample is acquired and stored in the computer's memory connected to the microscope. This acquired data is structured in proprietary formats, which are then transferred to the analysis computer over the network. In this model, there are significant limitations. The images acquired are not directly analyzed, and the generated data goes through two primary disk writes  - first at the acquisition computer, and second at the analysis computer. Network-enabled data acquisition can stream microscope data directly to the analysis computer, reducing the number of data writes. It also allows for online data analysis and presents quantitative information in the shortest possible time after data acquisition.

\paragraph*{} The execution of a plan in the current software is fixed, without scope for adjustments during a run. Error correction during the acquisition by stopping the existing imaging sequence from performing manual corrections could lead to discarded data or time points in the experiment. During offline analysis, it is often too late to influence the experiment or re-image the sample. Such problems are fundamental to microscopy technology and are faced by several others in fields such as super-resolution microscopy \cite{D1SC05506B}. In this section, it was identified that a redesign of the microscopy software architecture into a modular, closed-loop system by combining acquisition with analysis, with an event model and live streaming of information across the system, can unlock new experimental capabilities from existing hardware. This system is developed as hard-link, a device server, and deepthought, a closed-loop microscope data acquisition library.


\subsection{Controlling devices over a network server}
\paragraph*{} Microscope software can be thought of as abstractions of increasing complexity that work on top of each other. At the most basic level, the microscope software should be able to send commands to the device and receive responses. This is often known as the device control layer, which facilitates control at the hardware level. On the other hand, the device receives the command signal from the user, executes it, and sends a response. This communication to the device is often facilitated through a serial communication protocol. The device acts as a message parsing hub, which receives messages, performs actions and replies with data. Several devices associated with the microscope have to be tightly orchestrated to perform a series of tasks in the correct order to make practical applications of motorized microscopy for research purposes.

\paragraph*{} The primary role of microscope software is to interface with the hardware at the device level. This is generally achieved by drivers provided by manufacturers of devices. Drivers interface the communication of the device with the computer at the hardware and operating system level and can deliver high-level application programming interfaces (APIs) accessible through programming languages.

\paragraph*{} Micro-manager is open-source software for controlling motorized microscopes, where any device can be programmed to work with it using a Device Adapter \cite{edelstein2014advanced}. A wide range of devices for which Device Adapters are available in micro-manager can be accessed with a single interface called MMCore. A device configuration file is used to load and initialize the appropriate drivers, set presets or create a label for device positions. The host computer, to which the devices are connected, is where the micro-manager software is installed and the devices are configured appropriately (Fig. \ref{fig:hard_link}).

 \begin{figure}[h]
    {\hfill\includegraphics[width=0.7\linewidth]{figures/hard_link.png}\hspace*{\fill}}
    \caption{The system architecture of the device control server. Devices are connected to the hardware ports in the computer by cables. In the microscope computer, Device Adapters that are written in C++, bundled with micro-manager, manage the communication with the devices, and MMCore, which is the abstract model of a microscope as defined by micro-manager, is exposed to clients through TCP/IP. MMCore requires a configuration file with the various devices defined.}
    {\label{fig:hard_link}}
\end{figure}

\paragraph*{} To make micro-manager accessible over the network, the MMCore object is accessed through the python micro-manager interface, pymmcore, and wrapped around an RPyC Server object (Appendix. \ref{appx:rpc_server}). This effectively transforms device control into a network operation, where the MMCore control object is accessible as function calls to a client. To connect to the server, the client effectively provides the TCP/IP address of the server (Appendix. \ref{appx:rpc_client}). The significant advantage of this method of operation is that it separates the logic of the client application program from the device control server, making it easy to maintain the project with more efficient debugging. Termination of a client due to faulty logic does not affect the control server's status, preventing a catastrophic shutdown of the whole system.

\paragraph*{} Another significant advantage of this model is that the client can request the server for image data from a computer running any primary operating system that supports Python, allowing for a cross-platform operation of the microscope. With the development of the device control server, the next step in developing a microscope control software was to develop a layer of software abstraction for planning device execution sequences.

\subsection{Device orchestration planning with bluesky}

\begin{figure}[h]
    {\hfill\includegraphics[width=1\linewidth]{figures/control_loop.jpg}\hspace*{\fill}}
    \caption{Difference between open-loop and closed-loop software workflows for imaging a sample. In the open-loop system (right), after mounting a sample (centre), the user performs tasks with software, which includes finding the relevant regions of interest and defining an experimental plan from predefined experimentation patterns. Upon receiving a configuration, the system outputs raw data based on the experimental plan, which is the end point of such a system. Using deepthought, the sample is mounted by the user, and after that, a plan is executed, which involves a grid search for entities using detectors, and displays the quantitative properties of the sample in a dashboard. The quantitative data can be used as feedback to the experimental plans, which makes this a closed-loop system.}
    {\label{fig:control_loop}}
\end{figure}


\paragraph*{} With the control over the hardware with the device server, then becomes a matter of establishing a connection with the devices and orchestrating the order in which the devices are requested to perform a particular task programmatically. The device server can read and change the state of different motors and detectors (Appendix. \ref{appx:camera}, \ref{appx:focus}). To write elaborate sequences of hardware orchestration at a high-level, plans were written with the open-source python library bluesky, a spectroscopy-based data acquisition framework, which provides higher-level abstractions to define complex workflows, with access to methods to define redundancies, error-checking and data management (Appendix. \ref{appx:scope}) \cite{allan2019bluesky}.

\paragraph*{} In the bluesky framework, the devices are defined by the ophyd architecture, in which devices are abstracted as either motors or detectors, with the motor being a device whose position can be read and can be actuated to a new position. These objects are compatible with bluesky plans, which are a higher-level representation of the logic of the device orchestration sequence required for an experimental procedure. Once a bluesky plan is developed, it is executed at runtime by a RunEngine. The RunEngine interprets and executes the plan while communicating with hardware, monitoring for interruptions, organizing the data and metadata, and coordinating input/output. This architecture isolates the logic of the experimental procedure from the technical implementations of the device control instructions while also giving access to the data generated, along with proper handling of metadata and live visualization, among other things.

\paragraph*{} To write a typical microscopy experimental pattern in bluesky, such as a Z scan, one would have to define a FocusMotor (Appendix. \ref{appx:focus}) and a Camera ophyd object (Appendix. \ref{appx: camera}), with the access to the control layer defined in the set and read methods. From within a for loop on a range of distances to scan, either in absolute or relative terms, the atomic plans of mv or mvr from bluesky are called on the FocusMotor. A read interleaves each iteration of for loop on the camera. The results are a series of images, which vary in the Z-axis. Similar logic can be applied to scans involving any other motor devices, such as XYStage. Interestingly, one can also defines the camera's exposure as a motor and therefore define an exposure sweep with similar programming.

\paragraph*{} A RunEngine orchestrates the overall execution. It runs an asynchronous event loop that can run concurrent tasks along with hardware control. This separates the planning layer from the execution of device commands, and the management of data generated. Next, methods for online analysis have to be established. 


\subsection{Microscope model for closed-loop acquisition and analysis}
\paragraph*{}The software systems in commonly available wide-field systems can be characterized as open-loop systems. The user configures the microscope for a specific mode of operation by accessing device settings and configuring it manually. Some of these parameters are the position of the stage, z drive, mirrors, shutter, detector exposure, detector gain, choice of objective, etc. Existing software has customizable imaging profiles that can make it easier to set multiple device configurations at once and makes it easier to image specific dyes or imaging modes such as bright-field or phase contrast, all of which might require the actuation of entirely different parts of the microscope at once for the system to be ready before imaging. Apart from these, parameters such as focus, XY scan list, exposure time, and detector gain are optimally set to attain the best image possible by the system to perform further downstream offline analysis tasks. 

\paragraph*{} Tasks such as focus maintenance, centring cells in the field of view, observing cells in the x,y,z and t axis, and live tracking are essentially the higher level functionalities commonly used in an imaging experiment. Developing software patterns that combine acquisition and analysis can be riddled with function calls to several sub-systems, such as device control, observed patterns, image processing, statistical analysis, plotting, etc. Moreover, each of these functions calls to systems have further complexities. Designing a generalizable microscope software system for diverse user needs is still a challenge.

\paragraph*{} While designing deepthought, it was realized that the sample is often the focus of the experiment. A Sample can be defined as a physical object which contains biological entities of visual interest. Samples often have a geometric form of a dish, a rectangular slide, or dishes within a rectangular object (96-well plate) \ref{fig:form}. It is helpful to define the Sample entity, as it is separate from the instrumentation, and knowing the physical boundaries of the sample can be helpful in navigating it effectively. For instance, in the case of a confocal dish, it has to ensure that images are not acquired from the periphery of the coverslip area, where the light might refract differently through the glass and plastic, reducing the quality of the image. Since a confocal dish can be described as a circle, by inputting the centre of the dish and its diameter, the physical boundaries of the sample can be easily mapped for scanning onto the XY stage.


\begin{figure}[H]
    {\hfill\includegraphics[width=1\linewidth]{figures/form.jpg}\hspace*{\fill}}
    \caption{Top view of various sample forms commonly used in microscopes today. All samples have a physical form in 2D, such as a dish, slide or a large plate with multiple dishes. The top left features a confocal dish with a glass coverslip (yellow square) on the bottom,, providing a glass imaging surface (green) suitable for optical imaging. Other structural forms commonly used in imaging are also shown here, such as a rectangular glass coverslip (top right) and a multi-well plate with many isolated wells.}
    {\label{fig:form}}
\end{figure}


\paragraph*{} To develop an online analysis that is coupled to data acquisition, Frame objects are defined. Frames are objects that can hold imaging data as they are generated from RunEngine, interpret the plans, and perform operations on the images, such as object detection with Detectors or splitting of the polarization channels in the case of anisotropy imaging (Appendix. \ref{appx:frame_types}). Further statistical information about the detected objects from Frames, such as their position, shape, intensity values, etc., are stored in an Album object (Appendix. \ref{appx:objects}). Finally, the information within an Album is presented to the user by the visualization layer, essentially a live plot of an Album, a collection of detected objects from Frames (Fig. \ref{fig:arch}).

\begin{figure}[h]
    {\hfill\includegraphics[clip, width=1\linewidth]{figures/arch.jpg}\hspace*{\fill}}
    \caption{Software architecture of traditional systems, compared with deepthought, the closed-loop multi-layered system of modular planning, and sample abstraction. The device is connected physically to a computer, which acts as a control hub. In traditional systems, the entire stack of microscope control software is installed on this computer. The software has a control interface, which acts as a graphical interface for the user to input imaging parameters, translating into actuator control. In the case of deepthought, the device control computer is running the hard-link server, a wrapper for a micro-manager and a network server that receives command messages from a client. This facilitates actuator control in the hardware and returns data from the detectors and motors. Plans are run in a RunEngine, which concurrently runs the device orchestration sequence and emits data generated as a stream of events. These events are consumed by downstream functions that create an abstract model of the sample using computer vision object detectors, the results of which are then visualized by the user.}
    {\label{fig:arch}}
\end{figure}


\paragraph*{} In summary, $Objects$ such as the $Sample$ are $Entities$ which have a $GeometricForm$ of a $Dish$, or a $MultiWellPlate$, or a $Slide$ with known $OpticalProperties$, where $BiologicalObjects$ are grown, and $Scanned$ with the $XYStage$. $Images$ are encapsulated into $Frames$, upon which customizable $Detectors$ can detect various object types, and the detected objects are stored and visualized in a live $Album$.

\section{High-throughput mapping of fixed and live cells can be executed with deepthought}
\paragraph*{} Development of deepthought, an open-source full-stack microscope software system that could automatically image a large population of cells, with quantitative information displayed during imaging, opens up the possibility of investigating the heterogeneity in cellular responses to DNA damage.

\subsection{High-throughput dataset of damage responses are obtainable with deepthought}
\begin{figure}[h]
    {\hfill\includegraphics[clip, width=1\linewidth]{figures/if_ncs.png}\hspace*{\fill}}
    \caption{Representative image of immuno-fluorescence against $\gamma$H2AX (red) from a high-throughput dataset acquired with deepthought. Nuclei are stained with DAPI (blue). Cells were damaged with neocarzinostatin and fixed and stained for $\gamma$H2AX. Treated cells show increased staining of the antibody. }
    {\label{fig:ncs_ht}}
\end{figure}

\paragraph*{} Cells were treated with a radiomimetic DNA damage agent, neocarzinostatin (NCS) and fixed and stained for $\gamma$H2AX and phosphorylated Chk1 (Fig. \ref{fig:ncs_ht}). Damage response can be measured by the activation of proteins by post-translational modifications of specific amino acids that act as signalling events for DNA damage responses. $\gamma$H2AX and phosphorylated Chk1 are such markers. $\gamma$H2AX is the activated form of histone variant H2A.X, which is phosphorylated on serine in 139 by the PI3-family of kinases, especially ATM. $\gamma$H2AX is induced by a broad range of damages, making it a more general marker of damage \cite{kuo2008gamma}. This can be measured using antibodies against $\gamma$H2AX in an immunofluorescence assay. Chk1 is a kinase which coordinates the cell cycle checkpoint arrests during DNA damage responses. Activation of Chk1 due to phosphorylation by ATR leads to downstream effects such as cell cycle arrest, repair or death. Measuring $\gamma$H2AX and phosphorylated Chk1 gives a broader coverage of the activation of the signalling pathways in response to the damaging agents.

\begin{figure}[h]
    {\hfill\includegraphics[clip, width=1\linewidth]{figures/ncs.png}\hspace*{\fill}}
    \caption{Automated immuno-fluorescence imaging against $\gamma$H2AX and phosphorylated Chk1 with a sample size of N=11000 for control and treated each. Cells are treated with NCS. On the left is a scatter plot with the mean level of $\gamma$H2AX on the x-axis and the mean level of phosphorylated Chk1 on the y-axis, and each data point represents a cell. It can be observed that the mean levels of $\gamma$H2AX in treated cells are shifted to the right (positive increase in mean) without any shift in the levels of phosphorylated Chk1. The increase in the levels of $\gamma$H2AX can be seen in the histogram (centre), and the differences between the distribution are quantifiable with the cumulative density function (CDF) (right). There is a clear difference between the protein levels of $\gamma$H2AX in control and treated populations, as calculated with Kolmogorov–Smirnov statistics.
    {\label{fig:ncs}}}
\end{figure}


\paragraph*{} deepthought was used to map a larger sample size to get a finer resolution in the measurement of damage responses from immuno-fluorescence images of $\gamma$H2AX and phosphorylated Chk1 stained cells (Fig. \ref{fig:ncs_ht}). Damage response was induced in cells with treatment of 1$\mu$g/ml of neocarzinostatin (5 minutes, followed by 15 minutes recovery) which causes double strand-break damages. The system images a field at a time, processes it instantly and notifies the total N (sample size) identified during acquisition. A total of 22000 cells (11000 each for control and treatment) were imaged automatically with no human effort (Fig. \ref{fig:ncs}). Mean $\gamma$H2AX activation in treated cells was higher, without much change in phosphorylated Chk1 (Fig. \ref{fig:ncs} left). The distribution for $\gamma$H2AX for control and treatment was different, which was resolved by increasing the sampling size to a large extent. A sample size of 22000 cells in the dataset is far higher cell numbers than what is regularly done in microscopic investigations of DDR using everyday wide-field microscopes. High Content microscopes can achieve such numbers, but this solution has been implemented on a regular motorized wide-field microscope, increasing the breadth of such investigations.


\begin{figure}[h]
    {\hfill\includegraphics[clip, width=1\linewidth]{figures/mms_N.png}\hspace*{\fill}}
    \caption{\textcolor{red}{Automated immuno-fluorescence imaging against $\gamma$H2AX and phosphorylated Chk1 for increasing N in control and treatment of 0.02\% MMS (5 minutes, followed by 15 minutes recovery) show a subpopulation of treated cells. Scatter plot of $\gamma$H2AX against phosphorylated Chk1, histogram and cumulative density function of control and treatment levels of $\gamma$H2AX and phosphorylated Chk1, for increasing N of \textbf{(A)} 30, \textbf{(B)} 300, \textbf{(C)} 3000 and \textbf{(D)} 12,000 cells are plotted. Increasing N better resolves the population-level picture of protein expression, as shown by the finer resolution of the CDF. Rare subpopulations based on the levels of phosphorylated Chk1 can be observed in the scatter plots on the left, with increasing sampling size, which is quantified in the slope of the limiting histogram of phosphorylated Chk1. The limiting histogram is arrived at with increasing sample size. KS statistics and p values calculated with Kolmogorov–Smirnov test are plotted on the CDF.}}
    {\label{fig:mms_N}}
\end{figure}


\paragraph*{}Cells treated with 0.02\% methyl methanesulfonate (MMS), which methylates the bases and invokes the base excision repair (BER) and imaged for $\gamma$H2AX and phosphorylated Chk1 for N=12,000 cells each in control and treatment(Fig. \ref{fig:mms_N}D). It was observed that with increasing sample size, a picture emerged of subpopulations of responses characterized by a shift in the levels of phosphorylated Chk1. However, this phenomenon was not captured in the samples with low N (Fig. \ref{fig:mms_N}A). With the increase in N, the population level picture of more finely resolved. The large N also helped in arriving at a limiting histogram.


\subsection{Live imaging of damaged cells in high-throughput reveal rare phenomena in unsynchronized cells}
\paragraph*{} Since deepthought could image fixed cells in scale, the live cell imaging capabilities were tested by imaging an asynchronous population of cells expressing PCNA-chromobody to identify sub-populations of interest which would otherwise require synchronizing with chemical agents, like aphidicolin.

\begin{figure}[h]
    {\hfill\includegraphics[clip, width=0.8\linewidth]{figures/g1.png}\hspace*{\fill}}
    \caption{Automated microscopy identifies rare subpopulations of G1 cells undergoing repair sustained before cell division. Many fields of cells were imaged for 24 hours in control and treatment conditions. Both data sets selected cells with the morphology of G2 cells manually. In control conditions, G1 cells post mitosis show diffused PCNA signal, whereas 4NQO treated (1$\mu$g/ml for 15 minutes, followed by PBS wash) G1 cells show punctated PCNA, indicating ongoing repair from damage sustained in the parent cell and carried forward through mitosis. The arrows mark parent (left) and daughter cells (right). }
    {\label{fig:g1}}
\end{figure}

\paragraph*{} HeLa cells expressing PCNA-chromobody were imaged every 20 minutes for 24 hours with large sample size. Cells transitioning from S-phase to G2 and dividing into two G1 cells are more readily found from a large dataset of long-term time traces. Such cells can be used to track damage responses across cell cycle stages. PCNA-chromobody-expressing cells were treated with the UV-mimetic agent 4NQO and it was observed that PCNA is punctuated in non-S phase cells, which indicates foci of repair. 

\paragraph*{} Furthermore, by inspecting the timelapse of the cells going from S, G2, mitosis and into the two G1 daughter cells, it was also observed that damage foci were transferred to daughter G1 cells from a dividing mitotic cell (Fig. \ref{fig:g1}). This indicates that active repair foci are transferable across mitosis from parent cells to daughter cells. This required us to acquire data over hundreds of cells in an asynchronous population. Potentially such studies can be done by chemically arresting cells in specific stages of the cell cycle and then releasing them. However, such arrests themselves can alter measured responses, and there is value in performing studies in unperturbed asynchronous cultures.

\section{Discussion}
\paragraph*{} To combine the acquisition and analysis of microscope software, and to build on top of that, one would have to write a microscope control software from scratch. From a control system point of view, a microscope can be abstracted as a combination of motors and detectors. Motors are devices such as the filter wheel, objective turret, temperature control unit, condenser unit, etc., and detectors are the camera unit or a quadrant photo-diode that returns a sample reading. The challenge is to be able to communicate with these devices and be able to set and read the state parameters of these motors programmatically. Such as, reading the current position configuration of the filter wheel, or setting the objective turret to a new position. This can be abstracted as a set and read function for any motor-like device. Although in this implementation of deepthought architecture, the control system used is micro-manager, in principle, any abstract imaging and motor devices can be used with minimal changes, making this system versatile in imaging applications.

\paragraph*{} The establishment of fields of interest by manual inspection translates to a list of stage coordinates, with which the microscope executes an imaging sequence, resulting in the recording of data. Existing commercial software presents a model which can be characterized as an open control loop, where the chain of execution is linear, and there is no feedback in the system's operation (Fig. \ref{fig:control_loop} left).

\paragraph*{} The user takes the data from the microscope software and often starts a separate control sequence for image analysis, which results in quantifiable information that can be graphically represented to support the initial hypothesis. The analysis could be manually done with ImageJ, partially or fully automated with macros, or using other programming languages capable of image processing and statistical analysis, such as Python or Matlab \cite{haase2022hitchhiker}. This disconnect between the control sequences of imaging and analysis creates a gap in the experimental process that has to be bridged by the human user. In case the analysis reveals problems in imaging (such as focus drift, XY-drift, over or underexposed image, or insufficient sample size), there is no way for the analysis control sequence to make adjustments to the acquisition control sequence to compensate for low-quality data. Even if such compensations are done manually, it is time-consuming and might yield different experimental conditions for the user. Experiments with biological samples could be time-bound and have to be verified for quality at every acquisition step. Samples undergoing treatment conditions, or samples such as primary tissues are time-sensitive and cannot be imaged again once a time point has elapsed. Corrections would have to be performed online in case of any imaging failure. However, with the disconnect between acquisition and analysis, it is only sometimes possible to make such corrections with manual inspection at the time of acquisition, making this a high-effort endeavour.

\paragraph*{} Selection of cells from a population, based on their identity, can be an essential experimental toolkit for the future. One might often have to transiently transfect cells with a cocktail of plasmids (encoded as different colours in Fig. \ref{fig:control_loop} central panel). Usually, a plasmid's expression is verified with a fluorescent protein's expression. In the cases of a cocktail of plasmids (expressing different fluorescent proteins) transiently transfected in cells, one might expect a cell to express a random combination of the plasmids. Alternatively, one might be interested in imaging cells of specific cell cycle stages, such as mitotic or s-phase cells. In such scenarios, identifying fields of interest is a task of human persistence. The more effort one can spend in identifying fields of interest, one casts the broader net of observation on their objects of interest, therefore increasing the throughput of the experiment.

\paragraph*{} In summary, a microscope acquisition and analysis software was developed from scratch for hands-free high throughput imaging. In the context of DDR, the sample size of traditional immuno-fluorescence experiments can be enhanced mainly with a sample size greater than 10,000 without effort from the user. With increased throughput for live-cell imaging, it was seen that PCNA foci form in bona fide G1 cells created right after a mitosis event. Rare subpopulations could be identified in both fixed and live cell experiments. These are proof of concept examples, and the tools can be applied to various cell biological contexts that rely on similar experimental techniques. The project's source code is freely and openly available at \url{https://github.com/ndsystems/deepthought}. 


